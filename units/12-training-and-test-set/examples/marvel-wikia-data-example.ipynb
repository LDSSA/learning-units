{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marvel Wikia Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data originally from: [Comic Books Are Still Made By Men, For Men And About Men, by Walt Hickey for FiveThirtyEight](https://fivethirtyeight.com/features/women-in-comic-books/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available on GitHub (with details): [fivethirtyeight/data/comic-characters](https://github.com/fivethirtyeight/data/tree/master/comic-characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "% matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Deprecated\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the example data using the `read_csv` method from `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/marvel-wikia-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we will rename all columns to lower case and drop unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all columns to lower case\n",
    "data.columns = data.columns.str.lower()\n",
    "\n",
    "# Drop unnecessary columns 'urlslug' and 'gsm'\n",
    "data = data.drop(['urlslug', 'gsm'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>align</th>\n",
       "      <th>eye</th>\n",
       "      <th>hair</th>\n",
       "      <th>sex</th>\n",
       "      <th>alive</th>\n",
       "      <th>appearances</th>\n",
       "      <th>first appearance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1678</td>\n",
       "      <td>Spider-Man (Peter Parker)</td>\n",
       "      <td>Secret Identity</td>\n",
       "      <td>Good Characters</td>\n",
       "      <td>Hazel Eyes</td>\n",
       "      <td>Brown Hair</td>\n",
       "      <td>Male Characters</td>\n",
       "      <td>Living Characters</td>\n",
       "      <td>4043.0</td>\n",
       "      <td>Aug-62</td>\n",
       "      <td>1962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7139</td>\n",
       "      <td>Captain America (Steven Rogers)</td>\n",
       "      <td>Public Identity</td>\n",
       "      <td>Good Characters</td>\n",
       "      <td>Blue Eyes</td>\n",
       "      <td>White Hair</td>\n",
       "      <td>Male Characters</td>\n",
       "      <td>Living Characters</td>\n",
       "      <td>3360.0</td>\n",
       "      <td>Mar-41</td>\n",
       "      <td>1941.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id                             name               id            align  \\\n",
       "0     1678        Spider-Man (Peter Parker)  Secret Identity  Good Characters   \n",
       "1     7139  Captain America (Steven Rogers)  Public Identity  Good Characters   \n",
       "\n",
       "          eye        hair              sex              alive  appearances  \\\n",
       "0  Hazel Eyes  Brown Hair  Male Characters  Living Characters       4043.0   \n",
       "1   Blue Eyes  White Hair  Male Characters  Living Characters       3360.0   \n",
       "\n",
       "  first appearance    year  \n",
       "0           Aug-62  1962.0  \n",
       "1           Mar-41  1941.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The complete dataset containg 16376 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"The complete dataset contains %s rows and %s columns.\" % data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch. Doesn't generalize to new observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset contains 13100 rows and 10 columns.\n",
      "The test dataset contains 3276 rows and 10 columns.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(\"The training dataset contains %s rows and %s columns.\" % X_train.shape)\n",
    "print(\"The test dataset contains %s rows and %s columns.\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Train, validation and test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating different hyperparameters for estimators, there is still the risk of overfitting on the test set. To avoid knowledge about the test set to \"leak\" into the model, we may want to hold out a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this in a simple way, we can just use `train_test_split` twice: to split train from test, and test validation from train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset contains 10480 rows and 10 columns.\n",
      "The validation dataset contains 2620 rows and 10 columns.\n",
      "The test dataset contains 3276 rows and 10 columns.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=2)\n",
    "print(\"The training dataset contains %s rows and %s columns.\" % X_train.shape)\n",
    "print(\"The validation dataset contains %s rows and %s columns.\" % X_validation.shape)\n",
    "print(\"The test dataset contains %s rows and %s columns.\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By partitioning our data into three sets, we drastically reduce the number of samples which can be used for training, thus a lot of times this is not affordable nor desirable in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
